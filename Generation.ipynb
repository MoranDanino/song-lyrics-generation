{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Song Generation:"
      ],
      "metadata": {
        "id": "Ew1BFb3PwZZp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TnXW5ncZlI0D"
      },
      "outputs": [],
      "source": [
        "# imports\n",
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline, set_seed"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# set transformer seed\n",
        "set_seed(7)\n",
        "\n",
        "# mount drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# define path to folder - CHANGE TO WHICHEVER DIRECTORY YOU WANT\n",
        "path_folder_model = f\"/content/drive/MyDrive/Deep_Learning_project/model\"\n",
        "path_folder_tokenizer = f\"/content/drive/MyDrive/Deep_Learning_project/splits/tokenizer\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wsy-vGLmlN0w",
        "outputId": "97a61e8f-ed2b-4d09-e586-625301b2543e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load model\n",
        "\n",
        "# load pre-trained tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(path_folder_tokenizer)\n",
        "\n",
        "# load networks from folders\n",
        "model = AutoModelForCausalLM.from_pretrained(path_folder_model)\n",
        "\n",
        "model.resize_token_embeddings(len(tokenizer))\n",
        "\n",
        "\n",
        "# move models to GPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # if using GPU\n",
        "model = model.to(device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m6V767VKlOYU",
        "outputId": "f358e4eb-cb81-4bc4-a9d3-27de93feeb64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Song genre: (pop / rap / both)\n",
        "genre = \"both\" #@param {type: \"string\"}\n",
        "\n",
        "##@markdown Enter starting sentence (leave empty if you want to generate a song from the beggining):\n",
        "#start = \"\" # @param {type:\"string\"}\n",
        "\n",
        "#@markdown Number of generated songs:\n",
        "num_songs =  2 #@param {type:\"integer\"}\n",
        "\n",
        "#@markdown Parameters:\n",
        "max_length = 150 #@param {type:\"integer\"}\n",
        "temperature = 2.5 #@param {type:\"slider\", min:0.01, max:3.0, step:0.01}\n",
        "top_k = 50 #@param {type:\"integer\"}\n",
        "top_p = 0.8 #@param {type:\"slider\", min:0, max:1, step:0.01}\n",
        "repetition_penalty =  0.8 #@param {type:\"number\"}"
      ],
      "metadata": {
        "id": "AYauvu04lNyK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_songs(model, tokenizer, start, genre, num_songs, max_length, temp, top_k, top_p, repetition_penalty):\n",
        "\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    model.to(device)\n",
        "    # combine genre with starting text\n",
        "    full_prompt = f\"[Genre: {genre}] {start}\"  # Format the genre tag as used in training\n",
        "\n",
        "    # tokenize starting text\n",
        "    encoded_prompt = tokenizer.encode(full_prompt, add_special_tokens=False, return_tensors=\"pt\").to(device)\n",
        "\n",
        "    # generate output using model\n",
        "    output = model.generate(\n",
        "        input_ids=encoded_prompt,\n",
        "        max_length=max_length + encoded_prompt.shape[1], #len(encoded_prompt),\n",
        "        temperature=float(temp),\n",
        "        top_k=top_k,\n",
        "        top_p=float(top_p),\n",
        "        repetition_penalty=float(repetition_penalty),  # penalty on repeating phrases\n",
        "        do_sample=True,\n",
        "        num_return_sequences=num_songs\n",
        "    )\n",
        "\n",
        "    if len(output.shape) > 2:  # if more than one song\n",
        "        output.squeeze()  # squeeze in place\n",
        "\n",
        "    generated_songs = []  # initialize empty list for the generated songs\n",
        "    for i, sequence in enumerate(output):\n",
        "        sequence = sequence.tolist()\n",
        "        text = tokenizer.decode(sequence, skip_special_tokens=True)\n",
        "        generated_songs.append(text)\n",
        "    return generated_songs\n"
      ],
      "metadata": {
        "id": "dmbziScBlNv6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# generate the songs\n",
        "start = \"<sos>\""
      ],
      "metadata": {
        "id": "o_lWrnfLlNtJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "songs_rap = []\n",
        "songs_pop = []\n",
        "\n",
        "if genre == \"rap\" or genre == \"both\":\n",
        "    songs_rap = generate_songs(model, tokenizer, start, \"Rap\", num_songs, max_length, temperature, top_k, top_p, repetition_penalty)\n",
        "\n",
        "if genre == \"pop\" or genre == \"both\":\n",
        "    songs_pop = generate_songs(model, tokenizer, start, \"Pop\", num_songs, max_length, temperature, top_k, top_p, repetition_penalty)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IlP7MkwZlNqr",
        "outputId": "2e44dc4f-d9ea-4a8c-8d5b-890b9bf03a73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# post-processing\n",
        "def post_process(line):\n",
        "    line = line.replace(\"<sos>\", \"\")\n",
        "    line = line.replace(\"<pad>\", \"\")\n",
        "    line = line.replace(\"<eos>\", \"\")\n",
        "    return line"
      ],
      "metadata": {
        "id": "qFTjIHt9px6P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print results\n",
        "if genre == \"rap\" or genre == \"both\":\n",
        "    print(\"\\n----- Rap Song Output: -----\")\n",
        "    for i, song in enumerate(songs_rap):\n",
        "        print(f\"Song #{i + 1}:\\n\")\n",
        "        for line in song.replace(\", \", \",\\n\").replace(\". \", \".\\n\").replace(\": \", \":\\n\").replace(\"- \", \"-\\n\").replace(\"! \", \"!\\n\").replace(\"? \", \"?\\n\").split('\\n'):\n",
        "            processed_line = post_process(line)\n",
        "            print(processed_line)\n",
        "        print(\"\")\n",
        "\n",
        "if genre == \"pop\" or genre == \"both\":\n",
        "    print(\"\\n----- Pop Song Output: -----\")\n",
        "    for i, song in enumerate(songs_pop):\n",
        "        print(f\"Song #{i + 1}:\\n\")\n",
        "        for line in song.replace(\", \", \",\\n\").replace(\". \", \".\\n\").replace(\": \", \":\\n\").replace(\"- \", \"-\\n\").replace(\"! \", \"!\\n\").replace(\"? \", \"?\\n\").split('\\n'):\n",
        "            processed_line = post_process(line)\n",
        "            print(processed_line)\n",
        "        print(\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MmqlDmmspx3k",
        "outputId": "5b5ebd6e-3ef6-481f-fb50-90e8bf44f476"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "----- Rap Song Output: -----\n",
            "Song #1:\n",
            "\n",
            "  Lately,\n",
            "You have kept away some friends who want\n",
            "\n",
            "A different,\n",
            "but you stayed away from her\n",
            "In some distant and sometimes\n",
            "In some way they are gone \n",
            "That girl is your favorite boo,\n",
            " she's my everything\n",
            "The way you act\n",
            "Just be careful to put your emotions away\n",
            "No you'll need to look a\n",
            "\n",
            "A couple who be\n",
            "I could spend a life of me,\n",
            "in a couple of us\n",
            "\n",
            "Song #2:\n",
            "\n",
            "  I been grinding my time is  i been working hard I been taking all i know  I been trying i dont feel alone  i know its taking all i know its taking on taking my pain away i know my problems never stop I guess it is hard getting to see the light yeah so so yeah I wanna ride the world oh girl i never would never doubt oh i said no no no no yes me so me on ride\n",
            "Hood yeah my diamonds green it glo i got that i ain never stop so it be the pain yeah im on on to ride yeah yeah i just want some time away yeah my  yeah \n",
            "I been grinding yeah I been waiting wait all week now I got it yeah yeah yeah yeah and im working yeah yeah\n",
            "\n",
            "\n",
            "----- Pop Song Output: -----\n",
            "Song #1:\n",
            "\n",
            "  Hey,\n",
            "can anybody care,\n",
            "hey  who wanna feel like  who's so cold like them,\n",
            "and who wants to feel just like nobody feels.\n",
            "what happened  in America this,\n",
            "yeah the most crazy,\n",
            "how crazy can't anybody really give,\n",
            "and  who'd have believed in the best in humanity to have ever tried  to feel good,\n",
            "so that's the most   that can do it with nobody's so crazy about.\n",
            "you really feel so cold.\n",
            "who knows how big  the big hole you live in just don't think about  how many other  people who've come to this   it don't give that  like it can't give  to anyone that wants   to feel great.\n",
            "that is,\n",
            "oh,\n",
            "\n",
            "Song #2:\n",
            "\n",
            "  This song can save me\n",
            "\n",
            " We can sing but just because we won't know\n",
            "\n",
            "Well if we go\n",
            "So would you?\n",
            "We won't make this hurt a pain\n",
            "For I've got one of a sudden?\n",
            "So we may just fall apart\n",
            "\n",
            " I can see what is yours tonight\n",
            " And you see what is mine tonight\n",
            "\n",
            " My eyes can heal\n",
            " My heart could see everything's still\n",
            " Just another wasted breath inside \n",
            "My head hurts.\n",
            "I still think this shit out of the mind\n",
            "So let's start to let's just sit down\n",
            "\n",
            " Don't want this\n",
            " Just want this  You can start the fire.\n",
            "\n",
            " And make your fire come to life in just one shot.\n",
            "\n",
            " This song Can save\n",
            "\n"
          ]
        }
      ]
    }
  ]
}